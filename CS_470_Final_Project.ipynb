{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsONbciGog8s",
        "outputId": "69316ce2-8ebc-44f2-bef3-c7de2ce7c923"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "! rm -rf ~/.kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! echo '{\"username\":\"jademeskill\",\"key\":\"fe82fde46aeb72df41f1b111160c034b\"}' > ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! rm ./spambase.*\n",
        "! kaggle datasets download -d colormap/spambase\n",
        "! unzip ./spambase.zip\n",
        "! rm ./spambase.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "PjrEOQ3zonAS"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import pandas\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXyRfd35yRPd"
      },
      "source": [
        "# Naive bayes\n",
        "\n",
        "1. model learning:\n",
        "\n",
        "   Note:\n",
        "\n",
        "   features: remove attributes that is not related to word (the last four attributes)\n",
        "\n",
        "   labels: the last column\n",
        "\n",
        "   count P(c) -> how many samples are positive, and how many are negtive\n",
        "\n",
        "   if freq_word>0, then this word exists. You could use this to calculate P(a|c) -> for each class, what is the prob of each word\n",
        "\n",
        "   remember to use laplace smoothing.\n",
        "\n",
        "2. model evaluation (on val dataset -> performance(model, val)):\n",
        "   \n",
        "   for each new sample, $\\prod{P(a|c)}P(c)$; and find the maximum class\n",
        "   \n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "2-BayFlz7DAR"
      },
      "outputs": [],
      "source": [
        "class NaiveBayes:\n",
        "    def __init__(self, trainingData, validationData):\n",
        "        self.name = \"Gaussian Naive Bayes (with Laplace Smoothing)\"\n",
        "        self.actual = [row.iloc[-1] for _, row in validationData.iterrows()]\n",
        "        self.results = self.naiveBayes(trainingData, validationData)\n",
        "\n",
        "    def splitByClass(self, data):\n",
        "        separated = dict()\n",
        "        for index in range(len(data)):\n",
        "            vector = data.iloc[index].tolist()\n",
        "            classValue = vector[-1]\n",
        "            if classValue not in separated:\n",
        "                separated[classValue] = list()\n",
        "            separated[classValue].append(vector)\n",
        "        return separated\n",
        "\n",
        "    def summarizeDataset(self, data):\n",
        "        summaries = [(numpy.mean(column), numpy.std(column), len(column)) for column in zip(*data)]\n",
        "        summaries = summaries[:-1]\n",
        "        return summaries\n",
        "\n",
        "    def summarizeByClass(self, data):\n",
        "        separated = self.splitByClass(data)\n",
        "        summaries = dict()\n",
        "        for classValue, rows in separated.items():\n",
        "            summaries[classValue] = self.summarizeDataset(rows)\n",
        "        return summaries\n",
        "\n",
        "    def gaussianProbabilityDensity(self, x, mean, standardDeviation):\n",
        "        exponent = numpy.exp(-((x - mean) ** 2 / ((2 * standardDeviation ** 2) + 1e-17)))\n",
        "        return (1 / ((numpy.sqrt(2 * numpy.pi) * standardDeviation) + 1e-17)) * exponent\n",
        "\n",
        "    def calculateClassProbabilities(self, summaries, row):\n",
        "        totalRows = sum([summaries[label][0][2] for label in summaries])\n",
        "        totalClasses = len(summaries)\n",
        "        probabilities = dict()\n",
        "        for classValue, classSummaries in summaries.items():\n",
        "            probabilities[classValue] = (summaries[classValue][0][2] + 1)/(float(totalRows) + totalClasses)\n",
        "            for index in range(len(classSummaries)):\n",
        "                mean, standardDeviation, _ = classSummaries[index]\n",
        "                probabilities[classValue] *= self.gaussianProbabilityDensity(row.iloc[index], mean, standardDeviation)\n",
        "        return probabilities\n",
        "    \n",
        "    def predict(self, summaries, row):\n",
        "        probabilities = self.calculateClassProbabilities(summaries, row)\n",
        "        bestLabel, bestProbability = None, -1\n",
        "\n",
        "        for classValue, probability in probabilities.items():\n",
        "            if bestLabel is None or probability > bestProbability:\n",
        "                bestProbability = probability\n",
        "                bestLabel = classValue\n",
        "            \n",
        "        return bestLabel\n",
        "    \n",
        "    def naiveBayes(self, trainingData, validationData):\n",
        "        summaries = self.summarizeByClass(trainingData)\n",
        "        predictions = list()\n",
        "\n",
        "        for rowIndex in range(len(validationData)):\n",
        "            prediction = self.predict(summaries, validationData.iloc[rowIndex])\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jRvHTlW0DYA"
      },
      "source": [
        "# KNN\n",
        "1. model learning: None\n",
        "\n",
        "2. model evaluation(on val dataset): You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "\n",
        "   ```\n",
        "   Note:\n",
        "   parallel programing\n",
        "   numpy.cos() to calcuate the similarity\n",
        "   ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "-n-CrSO_LV4S"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, trainingData, validationData):\n",
        "        self.data = validationData\n",
        "        self.actual = [row.iloc[-1] for _, row in self.data.iterrows()]\n",
        "        self.results = self.evaluation(self.data)\n",
        "        self.name = \"KNN\"\n",
        "\n",
        "    def euclideanDistance(self, row1, row2):\n",
        "        distance = 0.0\n",
        "        for i in range(len(row1) - 1):\n",
        "            distance += (row1.iloc[i] - row2.iloc[i]) ** 2\n",
        "        return numpy.sqrt(distance)\n",
        "\n",
        "    def nearestNeighbors(self, data, testRow, numNeighbors):\n",
        "        distances = []\n",
        "\n",
        "        for _, row in data.iterrows():\n",
        "            distance = self.euclideanDistance(testRow, row)\n",
        "            distances.append((row, distance))\n",
        "\n",
        "        distances.sort(key=lambda tup: tup[1])\n",
        "        neighbors = list()\n",
        "        for index in range(numNeighbors):\n",
        "            neighbors.append(distances[index][0])\n",
        "        return neighbors\n",
        "\n",
        "    def predict(self, data, testRow, numNeighbors):\n",
        "        neighbors = self.nearestNeighbors(data, testRow, numNeighbors)\n",
        "        output = [row.iloc[-1] for row in neighbors]\n",
        "        prediction = max(set(output), key=output.count)\n",
        "        return prediction\n",
        "\n",
        "    def evaluation(self, data):\n",
        "        predictions = []\n",
        "        for _, row in data.iterrows():\n",
        "            predictions.append(self.predict(data, row, 5))\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUzUupva0Fxw"
      },
      "source": [
        "# LR\n",
        "\n",
        "1. model learning: You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "    \n",
        "    $y = sigmoid(MX)$\n",
        "\n",
        "step 1: add one more column (all value is 1) in X -> X' = np.c_[np.ones((len(X), 1)), X]\n",
        "\n",
        "step 2:vector M = np.random.randn(len(X[0])+1, 1);\n",
        "\n",
        "key formula for step 3 (Note: n is the size of the TRAINING dataset; $cdot$ is dot production ):\n",
        "\n",
        "1. $pred_y = sigmoid(M\\cdot X')$\n",
        "\n",
        "2. $loss = -\\sum(y\\cdot log(pred_y)+(1-y)\\cdot log(1-pred_y))/n$\n",
        "\n",
        "3. $gm=X'\\cdot (pred_y - y)*2/n$\n",
        "\n",
        "Step 3 example code:\n",
        "   ```\n",
        "   #Step 3: performing gradient descent on whole dataset:\n",
        "   best_model = M\n",
        "   best_performace = 0\n",
        "   for i in range(epoch):\n",
        "     pred_y = ...\n",
        "     gm = ...\n",
        "     _p = performace(model, val)\n",
        "     if _p > best_performance:\n",
        "        best_model = M\n",
        "        best_performance = _p\n",
        "     M = M - learning_rate*gm\n",
        "   ```\n",
        "\n",
        "2. model evaluation(on val dataset):\n",
        "  \n",
        "   calculate pred_y, if more than 0.5, then the predicted label is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "JbDj5NgAFw1L"
      },
      "outputs": [],
      "source": [
        "class LR:\n",
        "    def __init__(self, trainingData, validationData):\n",
        "        self.name = \"Logistic Regression\"\n",
        "        self.data = self.normalize(validationData, self.datasetMinMax(validationData))\n",
        "        self.actual = [row.iloc[-1] for _, row in self.data.iterrows()]\n",
        "        self.results = self.logisticRegression(trainingData, 0.1, 100, self.data)\n",
        "\n",
        "    def datasetMinMax(self, data):\n",
        "        minmax = list()\n",
        "        for index in range(len(data.columns)):\n",
        "            columns = [row.iloc[index] for _, row in data.iterrows()]\n",
        "            minVal = min(columns)\n",
        "            maxVal = max(columns)\n",
        "            minmax.append([minVal, maxVal])\n",
        "        return minmax\n",
        "    \n",
        "    def normalize(self, data, minmax):\n",
        "        for rowIndex in range(len(data)):\n",
        "            index = 0\n",
        "            for column in data.columns:\n",
        "                data.loc[rowIndex, column] = (data.iloc[rowIndex].loc[column] - minmax[index][0]) / (minmax[index][1] - minmax[index][0])\n",
        "                index += 1\n",
        "        return data\n",
        "\n",
        "    def predict(self, row, coefficients):\n",
        "        y = coefficients[0]\n",
        "        for index in range(len(row) - 1):\n",
        "            y += coefficients[index + 1] * row.iloc[index]\n",
        "        return 1.0 / (1.0 + numpy.exp(-y))\n",
        "\n",
        "    def stochasticGradientDescent(self, data, learningRate, epochs):\n",
        "        coefficient = [0.0 for i in range(len(data.iloc[0]))]\n",
        "        for epoch in range(epochs):\n",
        "            for _, row in data.iterrows():\n",
        "                y = self.predict(row, coefficient)\n",
        "                error = row.iloc[-1] - y\n",
        "                coefficient[0] = coefficient[0] + learningRate * error * y * (1.0 - y)\n",
        "                for i in range(len(row) - 1):\n",
        "                    coefficient[i + 1] = coefficient[i + 1] + learningRate * error * y * (1.0 - y) * row.iloc[i]\n",
        "        return coefficient\n",
        "\n",
        "    def logisticRegression(self, trainingData, learningRate, epochs, validationData):\n",
        "        predictions = list()\n",
        "        coefficient = self.stochasticGradientDescent(trainingData, learningRate, epochs)\n",
        "        for _, row in validationData.iterrows():\n",
        "            y = round(self.predict(row, coefficient))\n",
        "            predictions.append(y)\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAssSW_I0GvA"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "pm3wzEAc-KsS"
      },
      "outputs": [],
      "source": [
        "def performance(model, data):\n",
        "    actual = model.actual\n",
        "    results = model.results\n",
        "    result = {\"Confusion Matrix\": confusion_matrix(actual, results), \"Accuracy Score\": accuracy_score(actual, results), \"AUC Score\": roc_auc_score(actual, results)}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_vH9vty3CaQ",
        "outputId": "c06aff16-b283-4fb5-d600-db78d5a7ed19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.loc[rowIndex, column] = (data.iloc[rowIndex].loc[column] - minmax[index][0]) / (minmax[index][1] - minmax[index][0])\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.06271435570798628' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  data.loc[rowIndex, column] = (data.iloc[rowIndex].loc[column] - minmax[index][0]) / (minmax[index][1] - minmax[index][0])\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.14003409306143064' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  data.loc[rowIndex, column] = (data.iloc[rowIndex].loc[column] - minmax[index][0]) / (minmax[index][1] - minmax[index][0])\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.loc[rowIndex, column] = (data.iloc[rowIndex].loc[column] - minmax[index][0]) / (minmax[index][1] - minmax[index][0])\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:29: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0 / (1.0 + numpy.exp(-y))\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.loc[rowIndex, column] = (data.iloc[rowIndex].loc[column] - minmax[index][0]) / (minmax[index][1] - minmax[index][0])\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:29: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0 / (1.0 + numpy.exp(-y))\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.loc[rowIndex, column] = (data.iloc[rowIndex].loc[column] - minmax[index][0]) / (minmax[index][1] - minmax[index][0])\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:29: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0 / (1.0 + numpy.exp(-y))\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.loc[rowIndex, column] = (data.iloc[rowIndex].loc[column] - minmax[index][0]) / (minmax[index][1] - minmax[index][0])\n",
            "/var/folders/rw/6htvs5597dlbzktftzl1m4b00000gn/T/ipykernel_39868/51161119.py:29: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0 / (1.0 + numpy.exp(-y))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression\n",
            "\tAverage Time:  82.24754905700684\n",
            "\tAverage Accuracy:  0.6065894853263064\n",
            "\tAverage AUC Score:  0.5219215044008471\n",
            "\tAverage True Positives:  689\n",
            "\tAverage False Positives:  236\n",
            "\tAverage False Negatives:  296\n",
            "\tAverage True Negatives:  132\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "\n",
        "# Dataset\n",
        "data = pandas.read_csv(\"./spambase.csv\")\n",
        "data = data.sample(frac=1)\n",
        "\n",
        "training = data[:int(len(data)*.8)]\n",
        "test = data[int(len(data)*.8):]\n",
        "\n",
        "models = list()\n",
        "models.append(NaiveBayes)\n",
        "models.append(KNN)\n",
        "models.append(LR)\n",
        "\n",
        "fold5 = KFold(5)\n",
        "for model in models:\n",
        "    avgTime = 0.0\n",
        "    avgAcc = 0.0\n",
        "    avgAUC = 0.0\n",
        "    avgTP = 0\n",
        "    avgFP = 0\n",
        "    avgFN = 0\n",
        "    avgTN = 0\n",
        "    \n",
        "    for train_idx, val_idx in fold5.split(training):\n",
        "        sub_val = training.iloc[val_idx[0]:val_idx[-1]]\n",
        "        sub_train = training.iloc[train_idx[0]:train_idx[-1]]\n",
        "        startTime = time()\n",
        "        clf = model(sub_train, sub_val)\n",
        "        endTime = time() - startTime\n",
        "        result = performance(clf, test)\n",
        "        avgTime += endTime\n",
        "        avgAcc += result[\"Accuracy Score\"]\n",
        "        avgTP += result[\"Confusion Matrix\"][0][0]\n",
        "        avgFP += result[\"Confusion Matrix\"][0][1]\n",
        "        avgFN += result[\"Confusion Matrix\"][1][0]\n",
        "        avgTN += result[\"Confusion Matrix\"][1][1]\n",
        "        avgAUC += result[\"AUC Score\"]\n",
        "\n",
        "    print(clf.name)\n",
        "    print(\"\\tAverage Time: \", avgTime/5)\n",
        "    print(\"\\tAverage Accuracy: \", avgAcc/5)\n",
        "    print(\"\\tAverage AUC Score: \", avgAUC/5)\n",
        "    print(\"\\tAverage True Positives: \", int(avgTP/5))\n",
        "    print(\"\\tAverage False Positives: \", int(avgFP/5))\n",
        "    print(\"\\tAverage False Negatives: \", int(avgFN/5))\n",
        "    print(\"\\tAverage True Negatives: \", int(avgTN/5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
